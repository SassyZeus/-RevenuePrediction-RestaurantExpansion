{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hDk9hDvOH7",
        "outputId": "f44218c3-cb30-40bf-ae39-7a00d9a726e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install vecstack\n",
        "\n",
        "from vecstack import stacking\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->vecstack) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->vecstack) (3.2.0)\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwGQK7KAd7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282c578d-36af-4c0f-ee32-c8e4656efa1a"
      },
      "source": [
        "trainfile = r'/gdrive/My Drive/Preprocess_Train_Assignment4.csv'\n",
        "trainData = pd.read_csv(trainfile) #creates a dataframe\n",
        "testfile = r'/gdrive/My Drive/Preprocess_Test_Assignment4.csv'\n",
        "testData = pd.read_csv(testfile)  #creates a dataframe\n",
        "\n",
        "\n",
        "print(trainData.shape)\n",
        "print(testData.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(137, 44)\n",
            "(100000, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOTk6C1Ao45",
        "outputId": "1b68a6ef-7e05-4a37-fc17-e5cd07436bc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Extract training and test data\n",
        "y_train = trainData[\"revenue\"]\n",
        "X_train = trainData.drop([\"revenue\"], axis=1) #extracting training data without the target column\n",
        "print(X_train.shape)\n",
        "print(testData.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(137, 43)\n",
            "(100000, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained your Decision Tree model and made predictions\n",
        "clf = DecisionTreeRegressor()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Extract feature columns used during training\n",
        "feature_columns = X_train.columns\n",
        "\n",
        "# Extract test data\n",
        "# (Assuming 'revenue' is not present in the test set)\n",
        "X_test = testData\n",
        "\n",
        "# Preprocess the date column for test data\n",
        "X_test['Open Date'] = pd.to_datetime(X_test['Open Date'])\n",
        "X_test['year'] = X_test['Open Date'].dt.year\n",
        "X_test['month'] = X_test['Open Date'].dt.month\n",
        "X_test['day'] = X_test['Open Date'].dt.day\n",
        "\n",
        "# Drop the original date column and other unnecessary columns\n",
        "X_test = X_test.drop(['Open Date'], axis=1)\n",
        "\n",
        "# One-hot encode all non-numeric columns\n",
        "X_test = pd.get_dummies(X_test, columns=X_test.select_dtypes(include=['object']).columns)\n",
        "\n",
        "# Ensure columns in X_test match columns in X_train\n",
        "missing_columns = set(feature_columns) - set(X_test.columns)\n",
        "for col in missing_columns:\n",
        "    X_test[col] = 0\n",
        "\n",
        "# Reorder columns in X_test to match the order in X_train\n",
        "X_test = X_test[feature_columns]\n",
        "\n",
        "# Make predictions on the test set\n",
        "clf_predict_Test = clf.predict(X_test)\n",
        "\n",
        "# Save predictions\n",
        "df_DT = pd.DataFrame()\n",
        "df_DT['Prediction'] = clf_predict_Test\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "export_csv = df_DT.to_csv(r'/gdrive/My Drive/DT_Test17.csv')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IbUd_SkhLOOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9KXPcUtBE_E",
        "outputId": "65fedf7d-ba99-4df2-f689-d8bbb0104551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Assuming you have trained your Random Forest model and made predictions\n",
        "rfc = RandomForestRegressor()\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_predict_Train = rfc.predict(X_train)\n",
        "\n",
        "train_rmse = mean_squared_error(y_train, rfc_predict_Train)\n",
        "print(\"RMSE (training) for Random Forest: {:.6f}\".format(train_rmse))\n",
        "\n",
        "# Make predictions on the test set\n",
        "rfc_predict_Test = rfc.predict(X_test)\n",
        "\n",
        "# Save predictions\n",
        "df_RF = pd.DataFrame()\n",
        "df_RF['Prediction'] = rfc_predict_Test\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "export_csv = df_RF.to_csv(r'/gdrive/My Drive/RF_Test18.csv', index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (training) for Random Forest: 1020363853565.604126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PvfF2iAUU2I"
      },
      "source": [
        "#Save predictions\n",
        "df_rfc=pd.DataFrame()\n",
        "df_rfc['Predictions']=rfc_predict_Test\n",
        "export_csv = df_rfc.to_csv(r'/gdrive/My Drive/RF_Test19.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3D-s71uBJJJ",
        "outputId": "42a40468-4b98-4808-c28d-beb67b43883a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Gradient Boosting Regressor================================================================================\n",
        "\n",
        "abc = GradientBoostingRegressor()\n",
        "abc.fit(X_train, y_train)\n",
        "abc_predict_Train = abc.predict(X_train)\n",
        "\n",
        "train_rmse = mean_squared_error(y_train, abc_predict_Train)\n",
        "print(\"RMSE (training) for Gradient Boosting: {:.6f}\".format(train_rmse))\n",
        "\n",
        "# Make predictions on the test set\n",
        "abc_predict_Test = abc.predict(X_test)\n",
        "\n",
        "# Save predictions\n",
        "df_ABC = pd.DataFrame()\n",
        "df_ABC['Predictions'] = abc_predict_Test\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "export_csv = df_ABC.to_csv(r'/gdrive/My Drive/ABC_Test17.csv', index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (training) for Gradient Boosting: 211059290151.413116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwmX8AEOXvsA"
      },
      "source": [
        "#Save predictions\n",
        "df_abc=pd.DataFrame()\n",
        "df_abc['Predictions']=abc_predict_Test\n",
        "export_csv = df_abc.to_csv(r'/gdrive/My Drive/GB_Test17.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaI-s2FOetIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7653a54f-8220-4490-c3b3-e0035eed7047"
      },
      "source": [
        "# STACKING MODELS =====================================================================\n",
        "print(\"___________________________________________________________________________________________\\nEnsemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\\n\")\n",
        "\n",
        "models = [GradientBoostingRegressor(), RandomForestRegressor(), DecisionTreeRegressor()]\n",
        "\n",
        "S_Train, S_Test = stacking(models,\n",
        "                           X_train, y_train, X_test,\n",
        "                           regression=True,\n",
        "                           mode='oof_pred_bag',\n",
        "                           needs_proba=False,\n",
        "                           save_dir=None,\n",
        "                           n_folds=4,\n",
        "                           shuffle=True,  # Set shuffle to True\n",
        "                           random_state=42,  # Set a random_state value\n",
        "                           verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________________________________________________________________________________\n",
            "Ensemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\n",
            "\n",
            "task:         [regression]\n",
            "metric:       [mean_absolute_error]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [GradientBoostingRegressor]\n",
            "    fold  0:  [1727571.80164451]\n",
            "    fold  1:  [1878983.07222684]\n",
            "    fold  2:  [1670193.52098828]\n",
            "    fold  3:  [1867496.39775227]\n",
            "    ----\n",
            "    MEAN:     [1786061.19815298] + [89599.79705703]\n",
            "    FULL:     [1785634.26825146]\n",
            "\n",
            "model  1:     [RandomForestRegressor]\n",
            "    fold  0:  [1617860.18714286]\n",
            "    fold  1:  [1643741.91705882]\n",
            "    fold  2:  [1695464.07823529]\n",
            "    fold  3:  [2019925.07235294]\n",
            "    ----\n",
            "    MEAN:     [1744247.81369748] + [161596.00179977]\n",
            "    FULL:     [1743325.27627737]\n",
            "\n",
            "model  2:     [DecisionTreeRegressor]\n",
            "    fold  0:  [1982701.68571429]\n",
            "    fold  1:  [2370514.73529412]\n",
            "    fold  2:  [2094164.91176471]\n",
            "    fold  3:  [2062006.73529412]\n",
            "    ----\n",
            "    MEAN:     [2127347.01701681] + [146136.25115314]\n",
            "    FULL:     [2126291.21167883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBjpxzGXgZ_c"
      },
      "source": [
        "#STACKING - CONTRUCT A GRADIENT BOOSTING MODEL==============================\n",
        "model = GradientBoostingRegressor()\n",
        "\n",
        "model = model.fit(S_Train, y_train)\n",
        "y_pred_train = model.predict(S_Train)\n",
        "y_pred_test = model.predict(S_Test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvYtRVvbg84A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda71406-42f9-4ac6-e994-1a44b77461fa"
      },
      "source": [
        "mean_squared_error(y_train,y_pred_train)\n",
        "print(\"RMSE (training) for Decision Tree:{0:10f}\".format(mean_squared_error(y_train,y_pred_train)))\n",
        "#mean_squared_error(y_test,y_pred_test)\n",
        "#print(\"RMSE (Test Data) for Decision Tree:{0:10f}\".format(mean_squared_error(y_test,y_pred_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (training) for Decision Tree:399110582712.695801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J51JbjDyiGET"
      },
      "source": [
        "#Save predictions\n",
        "df_stacking=pd.DataFrame()\n",
        "df_stacking['Prediction']=y_pred_test\n",
        "export_csv = df_rfc.to_csv(r'/gdrive/My Drive/Stacking_Test17.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the base models\n",
        "models = [\n",
        "    ('gb', GradientBoostingRegressor()),\n",
        "    ('rf', RandomForestRegressor()),\n",
        "    ('dt', DecisionTreeRegressor())\n",
        "]\n",
        "\n",
        "# Define the meta-model\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Create the stacked model\n",
        "stacked_model = StackingRegressor(estimators=models, final_estimator=meta_model)\n",
        "\n",
        "# Define parameters for grid search\n",
        "param_grid = {\n",
        "    'gb__n_estimators': [50, 100, 200],\n",
        "    'gb__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'gb__max_depth': [3, 5, 7],\n",
        "    'rf__n_estimators': [50, 100, 200],\n",
        "    'rf__max_depth': [None, 10, 20],\n",
        "    'rf__min_samples_split': [2, 5, 10],\n",
        "    'dt__max_depth': [None, 5, 10],\n",
        "    'dt__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning using GridSearchCV\n",
        "grid_search = GridSearchCV(stacked_model, param_grid, scoring=make_scorer(mean_squared_error, greater_is_better=False), cv=4)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Score: {grid_search.best_score_}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "stacked_predict_Test = grid_search.predict(X_test)\n",
        "\n",
        "# Save predictions\n",
        "df_stacked = pd.DataFrame({'Prediction': stacked_predict_Test})\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "export_csv = df_stacked.to_csv(r'/gdrive/My Drive/Stacked_Model_Predictions.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "wfsasiN6WFlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nb5I3mcFWHRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}